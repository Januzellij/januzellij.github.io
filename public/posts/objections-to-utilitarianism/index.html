<!DOCTYPE html>
<html lang="en-us">
  <head>
    <title>Some Objections to Utilitarianism | Beneath the Piled Centuries</title>

    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">    
<meta name="viewport" content="width=device-width,minimum-scale=1">
<meta name="description" content="I want to go over some objections I have with utilitarianism. Partially this is for my own selfish benefit so I can stop thinking about this all the time, but it‚Äôs also because most laymen/naive objections to utilitarianism that I‚Äôve encountered are very weak (some examples here). This weakness comes from the fact that the way utilitarianism is presented is ingenious, to the point that is seems like the correct ethical system ipso facto; a paragon of rationality floating far above the teeming, grimy hoards of common folk.">
<meta name="generator" content="Hugo 0.92.0" />


  <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">


<link rel="stylesheet" href="/css/style.css">



<link rel="shortcut icon" href="/images/favicon.ico" type="image/x-icon" />




  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.js" integrity="sha384-VQ8d8WVFw0yHhCk5E8I86oOhv48xLpnDZx5T9GogA/Y84DcCKWXDmSDfn13bzFZY" crossorigin="anonymous"></script>

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/contrib/auto-render.min.js" integrity="sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>





  </head>

  <body>
    <nav class="navigation">
	
		<a href="/"> <span class="arrow">‚Üê</span>Home</a>
	
	<a href="/posts">Archive</a>
	<a href="/tags">Tags</a>
	<a href="/about">About</a>

	

	
</nav>


    <main class="main">
      

<section id="single">
    <h1 class="title">Some Objections to Utilitarianism</h1>

    <div class="tip">
        <time datetime="2022-09-11 10:32:12 -0500 CDT">Sep 11, 2022</time>
        <span class="split">
          ¬∑
        </span>
        <span>
          1842 words
        </span>
        <span class="split">
          ¬∑
        </span>
        <span>
          9 minute read
        </span>
    </div>

    
    


    <div class="content">
      <p>I want to go over some objections I have with utilitarianism. Partially this is for my own selfish benefit so I can stop thinking about this all the time, but it‚Äôs also because most laymen/naive objections to utilitarianism that I‚Äôve encountered are very weak (some examples <a href="https://sandhoefner.com/2017/10/27/in-defense-of-utilitarianism/" target="_blank" rel="noopener">here</a>). This weakness comes from the fact that the way utilitarianism is presented is ingenious, to the point that is seems like the correct ethical system ipso facto; a paragon of rationality floating far above the teeming, grimy hoards of common folk. On the contrary, utilitarianism is ad hoc and relies on massive unjustified assumptions. It is a failure of secular rationality: the rationalist scorns antiquated moral systems, with their unjustified assumptions and myopic view of the world, before embracing an ethical system with far more egregious assumptions and a modern coat of paint.</p>
<p>Let‚Äôs look at an example. Suppose I am a utilitarian farmer who‚Äôs considering putting pesticides on my crops to get rid of a beetle infestation. To make this decision, I must know how much utility my harvest will give to the people that consume it, the likelihood the pesticides make a difference, and what the worth is of the lives of the insects my pesticides kill. I can then compare these numbers and see what the expected utility is of applying the pesticides.</p>
<h2 id="utility-makes-no-sense">Utility makes no sense <a href="#utility-makes-no-sense" class="anchor">üîó</a></h2><p>Utility, as a concept, makes no sense. There is no reason to believe that there is some number \( N \), so that one human life is worth \( N \) beetle lives. Sure, you can assign a number, but it‚Äôs all garbage. What information is this going to be based upon? What possibly functions as a reasonable explanation here? What would be a convincing argument that, for examples, \( N \) should be at least \( 10,000 \)?</p>
<p>There are &ldquo;workarounds&rdquo; here that seem reasonable, but are just serpentine tricks. For example, someone may ask how much money you‚Äôre willing to pay to have/not have an experience, and then build utility based on that. This is a fake question though: the answers aren‚Äôt based on anything, they‚Äôre random shots in the dark. People do not have the ability, psychologically, to evaluate experiences in this way. It‚Äôs analogous to Anselm is making the ontological argument for the existence of God and saying ‚ÄúI can conceive of a supremely perfect being‚Äù which he obviously can&rsquo;t, and is deluding himself.s</p>
<p>In this light, it is clearer why the slogan of utilitarianism, ‚Äúthe greatest amount of good‚Äù is so deceptive. Whether one says ‚Äúgood‚Äù, ‚Äúwell-being‚Äù, ‚Äúhappiness‚Äù, ‚Äúutility‚Äù, or something else, this word is devoid of meaning. There is no singular entity called ‚ÄúUtility‚Äù that captures positive subjective experiences across all agents in a unified way. ‚ÄúUtility‚Äù functions as a pseudo-Platonic Form of the Good to marshal wildly different modalities under a common umbrella. Its very existence is a metaphysical axiom of gargantuan proportions.</p>
<p>Not only are experiences incomparable, they aren‚Äôt even accessible. To compare the lives of the beetles to the lives of the humans who eat my crops, I need to have a <em>quantitative measure</em> of the subjective experience of a beetle. Quantitative is the key word here: there are obviously ways we can infer what the subjective experience of other agents is, otherwise we couldn‚Äôt operate as people. However, this requires that subjective experiences are physical entities that can be measured, and I don‚Äôt see any reason this should be true.</p>
<p>This topic is covered in more detail in Thomas Nagel‚Äôs paper <a href="https://warwick.ac.uk/fac/cross_fac/iatl/study/ugmodules/humananimalstudies/lectures/32/nagel_bat.pdf" target="_blank" rel="noopener">What is it like to be a bat?</a>.</p>
<p>The utilitarian may object here that I‚Äôm being extreme. Does this mean that we can‚Äôt ever know anything about what other entities are thinking or how they are suffering? If so, it seems that people can do harm to any other living thing they want, since we have no idea of their subjective experience, and correspondingly whether they <em>actually</em> suffer.</p>
<p>However, I‚Äôm not being extreme at all. The implicit assumption here is that the reason we choose to not harm other entities is because we have some sort of knowledge of their subjective experience, but this assumption just isn‚Äôt true in day-to-day life. Deontological systems don‚Äôt require any knowledge of other beings subjective experience, nor does following your moral instincts. It is a <em>strength</em> to ignore subjective experience in this way, not a weakness. Instead, subjective experience can be inferred from other sources, like how another entity communicates or behaves. These non-utilitarian systems take into account subjective experience by lessening the burden of proof: no neuroscience necessary. The key flaw here is not that utilitarianism accounts for subjective experience, but that utilitarian epistemology is unnecessarily restrictive.</p>
<p>The utilitarian may also object to the idea that implementation is part of the utilitarian package. They may claim that utilitarianism merely defines what is moral and immoral, and it is the task of science to determine how best to implement these directives.</p>
<p>This is a cop-out argument for a few reasons. Firstly, the objection to implementation relating to accessibility of subjective experience is not something that can be solved with advancing technology or science: it is a hard philosophical barrier. Secondly, even if I buy this argument, it leaves the utilitarian in a bad position. They now are defending an ethical system that, <em>by their own admission</em>, is currently a mere academic exercise, and one that is not able to be put into practice. Finally, utilitarianism without a reasonable implementation is, in practice, deontological: some government or think tank or other institution says that they did the calculations and it just so happens that utilitarianism supports whatever bullshit the institution is currently on about. What a surprise.</p>
<p>Another theoretical problem with utilitarianism is that expected utility is inapproximable. In an expected utility calculation, there are two factors that affect how much a hypothetical situation matters: the probability that it occurs, and the potential effect on total utility. (Technically utilitarians don&rsquo;t have to necessarily use expected utility, but whatever mathematical framework they end up using will depend principally on the same two factors). The problem here is that the potential effect on total utility is arbitrary: the utilitarian now has to give serious credence to any insane hypothetical, as long as the potential effect on utility is high enough.</p>
<p>There are many examples of this: I‚Äôll give a few.</p>
<p>A fairly pedestrian one goes as follows: suppose a government is considering banning farming animals for consumption. Because of the potentially massive effect on total utility, they have to take into consideration the possibility that animals gain substantial utility from being killed and eaten in large numbers. Maybe farm animals are masochists and derive huge pleasure from their execution. Or maybe they‚Äôre religious, and it is part of their religion that they are ritually killed for consumption.</p>
<p>A classic instance is a variant on the famous Pascal‚Äôs Wager, called Pascal‚Äôs Mugging (<a href="https://wiki.lesswrong.com/wiki/Pascal%27s_mugging%29" target="_blank" rel="noopener">https://wiki.lesswrong.com/wiki/Pascal%27s_mugging)</a>. One night as you‚Äôre walking home, a man steps out of the shadows and demands $5, which you have on you. If you refuse, he will kill 3 billion people in an excruciatingly painful way by using his magic powers. Again, the premise is supposed to be ridiculous: the issue here is that, <em>merely through his words</em>, he has forced his way into serious consideration, irrespective of how insane the premise is.</p>
<p>Finally, here is an exhaustive exploration of the question of whether fundamental particles (electrons, quarks, etc) suffer (<a href="https://reducing-suffering.org/is-there-suffering-in-fundamental-physics/%29" target="_blank" rel="noopener">https://reducing-suffering.org/is-there-suffering-in-fundamental-physics/)</a>.</p>
<p>The common theme here is that these possibilities are nuts, but there isn&rsquo;t a reliable way to shrink confidence intervals small enough to get a positive outcome. Take the farming example. Suppose the potential pleasure of animals being slaughtered would be \( 10^{100} \) utils. It is very unlikely that animals enjoy being slaughtered in this way, but who&rsquo;s to put an estimate on the likelihood? Is the probability less than \( 10^{-100} \)? \( 10^{-1000} \)? What on earth would this estimation be based on? Because the potential utility is so high, whether the likelihood is \( 10^{-100} \) or \( 10^{-1000} \) is the difference between a stubbed toe and the Holocaust.</p>
<h2 id="practical-objections">Practical objections <a href="#practical-objections" class="anchor">üîó</a></h2><p>After all of this nit-picking over epistemology, maybe my biggest problem with utilitarianism is that it is completely alien. It in no way considers the actual psychology of living people, and the things that our brains have been selected over time to do. It is something you invent without any knowledge of human psychology: the creation of ethical principles completely removed from the necessary historical context. The utilitarian treats human brains like computers whose function is to crunch numbers and treat everyone with the same brush of impartiality.</p>
<p>The moral framework that we are equipped with through instincts and moral intuitions is astonishingly effective at accomplishing a specific task: maintaining close social groups in a way that aids the survival of the species. Utilitarianism is designed to &ldquo;be correct&rdquo;. However, moral systems are bound by sociological measures beyond &lsquo;philosophical correctness&rsquo;: they have to inspire everyone to do their best and allow timely and fair resolution of conflicts.</p>
<p>To take a concrete example, utilitarianism dictates that in many cases, wealthier people will be more moral - not because of any actual moral facets of their character, but by the mere fact that they have more discretionary capital available to them.</p>
<p>Suppose John makes $50k a year and Jack makes $60k a year. They both have the same amount of &lsquo;hard&rsquo; expenses (food, rent, car, etc.). Let&rsquo;s say those are $35k a year. They both allocate their income after these expenses have been withdrawn in the same way percentage-wise. and give the same percent of discretionary income (money they have after taking card of hard expenses) to the same charity. If the other discretionary activities are not wildly immoral, in the end Jack will end up being more moral by utilitarian standards, simply because he had a larger pool to start with.</p>
<p>This is a sociologically moronic maxim, directly antithetical to social cohesion, but by all accounts this is not something that utilitarians care much about (just look at Singer&rsquo;s op-ed on the Anna Stubblefield case). And in the end, this is what matters. It is no accident that people who identify as utilitarians are invariably rich nerds who deprioritize moral acts that necessitate interactions face-to-face and heart-to-heart. It&rsquo;s far easier to shave a zero or two off your bank account and continue your morally superior day.</p>
<p><em>Jesus sat down opposite the place where the offerings were put and watched the crowd putting their money into the temple treasury. Many rich people threw in large amounts. But a poor widow came and put in two very small copper coins, worth only a fraction of a penny. Calling his disciples to him, Jesus said &ldquo;I tell you the truth, this poor widow has put more into the treasury than all the others. They all gave out of their wealth; but she, out of her poverty, put in everything&ndash;all she had to live on&rdquo;. (Mark 12:41-44, NIV)</em></p>

    </div>

    
    
    

</section>


    </main>
    
    <footer id="footer">
    

    <div class="copyright">
    
       ¬© Copyright 
       2022 
       <span class="split">
        <svg fill="#bbbbbb" width="15" height="15" version="1.1" id="heart-15" xmlns="http://www.w3.org/2000/svg" width="15px" height="15px" viewBox="0 0 15 15">
  <path d="M13.91,6.75c-1.17,2.25-4.3,5.31-6.07,6.94c-0.1903,0.1718-0.4797,0.1718-0.67,0C5.39,12.06,2.26,9,1.09,6.75&#xA;&#x9;C-1.48,1.8,5-1.5,7.5,3.45C10-1.5,16.48,1.8,13.91,6.75z"/>
</svg>
       </span>
       
    
    </div>

    
      <div class="powerby">
        Powered by <a href='http://www.gohugo.io/'>Hugo</a> Theme By <a href='https://github.com/nodejh/hugo-theme-cactus-plus'>nodejh</a>
      </div>
    
</footer>



  </body>
</html>
